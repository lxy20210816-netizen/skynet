#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨Seleniumè·å–Twitteræ¨æ–‡ï¼ˆæ— éœ€APIï¼‰
é€šè¿‡æµè§ˆå™¨è‡ªåŠ¨åŒ–æŠ“å–Twitterå…¬å¼€æ¨æ–‡
"""

import sys
import json
import time
import argparse
from datetime import datetime
import os
import re

try:
    from selenium import webdriver
    from selenium.webdriver.chrome.service import Service
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.common.by import By
    from selenium.webdriver.common.keys import Keys
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.common.exceptions import TimeoutException, NoSuchElementException
except ImportError:
    print("âŒ è¯·å…ˆå®‰è£…selenium: pip install selenium", file=sys.stderr)
    sys.exit(1)


def setup_driver(headless=True):
    """é…ç½®å¹¶å¯åŠ¨Chromeæµè§ˆå™¨"""
    chrome_options = Options()
    if headless:
        chrome_options.add_argument('--headless')  # æ— å¤´æ¨¡å¼
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--disable-gpu')
    chrome_options.add_argument('--window-size=1920,1080')
    chrome_options.add_argument('--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
    chrome_options.add_argument('--disable-blink-features=AutomationControlled')
    
    # ç¦ç”¨è‡ªåŠ¨åŒ–æ£€æµ‹
    chrome_options.add_experimental_option('excludeSwitches', ['enable-automation'])
    chrome_options.add_experimental_option('useAutomationExtension', False)
    
    # æ·»åŠ è¯­è¨€è®¾ç½®
    chrome_options.add_argument('--lang=en-US')
    
    try:
        driver = webdriver.Chrome(options=chrome_options)
        return driver
    except Exception as e:
        print(f"âŒ å¯åŠ¨æµè§ˆå™¨å¤±è´¥: {e}", file=sys.stderr)
        print("è¯·ç¡®ä¿å·²å®‰è£…Chromeæµè§ˆå™¨", file=sys.stderr)
        sys.exit(1)


def login_twitter(driver, username=None, password=None):
    """ç™»å½•Twitterï¼ˆå¯é€‰ï¼‰"""
    if not username or not password:
        return False
    
    try:
        print("ğŸ” æ­£åœ¨ç™»å½•Twitter...", file=sys.stderr)
        driver.get("https://twitter.com/i/flow/login")
        time.sleep(8)
        
        # è¾“å…¥ç”¨æˆ·å/é‚®ç®±å¹¶æŒ‰Enter
        try:
            username_input = WebDriverWait(driver, 15).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, 'input[autocomplete="username"]'))
            )
            username_input.clear()
            username_input.send_keys(username)
            username_input.send_keys(Keys.ENTER)
            print("âœ“ å·²è¾“å…¥ç”¨æˆ·åå¹¶æäº¤", file=sys.stderr)
            time.sleep(5)
        except Exception as e:
            print(f"âš ï¸  è¾“å…¥ç”¨æˆ·åå¤±è´¥: {e}", file=sys.stderr)
            raise
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é¢å¤–éªŒè¯ï¼ˆé‚®ç®±/ç”µè¯ï¼‰
        time.sleep(3)
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰é¢å¤–è¾“å…¥æ¡†ï¼ˆé‚®ç®±éªŒè¯ç­‰ï¼‰
            extra_inputs = driver.find_elements(By.CSS_SELECTOR, 'input[data-testid="ocfEnterTextTextInput"]')
            if extra_inputs:
                print("âš ï¸  æ£€æµ‹åˆ°é¢å¤–éªŒè¯æ­¥éª¤ï¼Œå¯èƒ½éœ€è¦è¾“å…¥é‚®ç®±æˆ–ç”µè¯", file=sys.stderr)
                # å°è¯•è¾“å…¥ç”¨æˆ·åçš„é‚®ç®±éƒ¨åˆ†
                extra_inputs[0].send_keys(username)
                extra_inputs[0].send_keys(Keys.ENTER)
                time.sleep(5)
        except:
            pass
        
        # è¾“å…¥å¯†ç å¹¶æŒ‰Enter
        try:
            password_input = WebDriverWait(driver, 15).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, 'input[name="password"]'))
            )
            password_input.clear()
            password_input.send_keys(password)
            password_input.send_keys(Keys.ENTER)
            print("âœ“ å·²è¾“å…¥å¯†ç å¹¶æäº¤", file=sys.stderr)
            time.sleep(10)
        except Exception as e:
            print(f"âš ï¸  è¾“å…¥å¯†ç å¤±è´¥: {e}", file=sys.stderr)
            # å°è¯•å…¶ä»–å¯†ç è¾“å…¥æ¡†
            try:
                password_inputs = driver.find_elements(By.CSS_SELECTOR, 'input[type="password"]')
                if password_inputs:
                    password_inputs[0].clear()
                    password_inputs[0].send_keys(password)
                    password_inputs[0].send_keys(Keys.ENTER)
                    print("âœ“ å·²è¾“å…¥å¯†ç ï¼ˆå¤‡ç”¨æ–¹å¼ï¼‰", file=sys.stderr)
                    time.sleep(10)
                else:
                    raise
            except:
                raise
        
        # æ£€æŸ¥æ˜¯å¦ç™»å½•æˆåŠŸ
        time.sleep(5)
        current_url = driver.current_url
        if 'home' in current_url or 'i/flow' not in current_url:
            print("âœ… ç™»å½•æˆåŠŸ", file=sys.stderr)
            return True
        else:
            print("âš ï¸  ç™»å½•å¯èƒ½å¤±è´¥ï¼Œç»§ç»­å°è¯•...", file=sys.stderr)
            return False
            
    except Exception as e:
        print(f"âš ï¸  ç™»å½•å¤±è´¥: {e}", file=sys.stderr)
        print("ç»§ç»­ä»¥æœªç™»å½•çŠ¶æ€æŠ“å–ï¼ˆå¯èƒ½åªèƒ½è·å–éƒ¨åˆ†æ¨æ–‡ï¼‰", file=sys.stderr)
        return False


def load_cookies(driver, cookie_file='config/twitter_cookies.json'):
    """åŠ è½½ä¿å­˜çš„cookies"""
    try:
        if not os.path.exists(cookie_file):
            return False
        
        print(f"ğŸª åŠ è½½cookies: {cookie_file}", file=sys.stderr)
        
        # å…ˆè®¿é—®Twitterä¸»é¡µï¼ˆå¿…é¡»å…ˆè®¿é—®æ‰èƒ½æ·»åŠ cookiesï¼‰
        driver.get("https://twitter.com")
        time.sleep(3)
        
        with open(cookie_file, 'r') as f:
            cookies = json.load(f)
        
        for cookie in cookies:
            try:
                driver.add_cookie(cookie)
            except:
                pass
        
        print(f"âœ… å·²åŠ è½½ {len(cookies)} ä¸ªcookie", file=sys.stderr)
        return True
    except Exception as e:
        print(f"âš ï¸  åŠ è½½cookieså¤±è´¥: {e}", file=sys.stderr)
        return False


def scrape_tweets(username, num_tweets=10, twitter_user=None, twitter_pass=None, use_cookies=True):
    """
    ä½¿ç”¨SeleniumæŠ“å–Twitteræ¨æ–‡
    """
    print(f"ğŸ¦ æ­£åœ¨è·å– @{username} çš„æ¨æ–‡...", file=sys.stderr)
    print("ğŸŒ å¯åŠ¨æµè§ˆå™¨...", file=sys.stderr)
    
    driver = setup_driver()
    tweets = []
    logged_in = False
    
    try:
        # ä¼˜å…ˆå°è¯•ä½¿ç”¨ä¿å­˜çš„cookies
        if use_cookies:
            logged_in = load_cookies(driver)
        
        # å¦‚æœcookieså¤±è´¥ä¸”æä¾›äº†ç™»å½•ä¿¡æ¯ï¼Œå°è¯•ç™»å½•
        if not logged_in and twitter_user and twitter_pass:
            logged_in = login_twitter(driver, twitter_user, twitter_pass)
        
        if not logged_in:
            print("âš ï¸  æœªç™»å½•çŠ¶æ€è®¿é—®ï¼ˆå¯èƒ½å—é™ï¼‰", file=sys.stderr)
            print("ğŸ’¡ æç¤ºï¼šè¿è¡Œ 'python3 scripts/twitter_save_cookies.py' æ‰‹åŠ¨ç™»å½•å¹¶ä¿å­˜cookies", file=sys.stderr)
        
        # è®¿é—®ç”¨æˆ·ä¸»é¡µ
        url = f"https://twitter.com/{username}"
        print(f"ğŸ“± è®¿é—®: {url}", file=sys.stderr)
        driver.get(url)
        
        # ç­‰å¾…é¡µé¢åŠ è½½
        print("â³ ç­‰å¾…é¡µé¢åŠ è½½...", file=sys.stderr)
        time.sleep(8)
        
        # æ£€æŸ¥é¡µé¢æ ‡é¢˜å’ŒçŠ¶æ€
        page_title = driver.title
        print(f"ğŸ“„ é¡µé¢æ ‡é¢˜: {page_title}", file=sys.stderr)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰"è´¦å·è¢«æš‚åœ"ç­‰æç¤º
        try:
            body_text = driver.find_element(By.TAG_NAME, 'body').text
            if 'è´¦å·è¢«æš‚åœ' in body_text or 'suspended' in body_text.lower() or 'Account suspended' in body_text:
                print(f"âš ï¸  è´¦å·å¯èƒ½è¢«æš‚åœæˆ–é™åˆ¶", file=sys.stderr)
        except:
            pass
        
        # æ»šåŠ¨é¡µé¢åŠ è½½æ›´å¤šæ¨æ–‡
        last_height = driver.execute_script("return document.body.scrollHeight")
        scroll_attempts = 0
        max_scrolls = 50  # æœ€å¤šæ»šåŠ¨50æ¬¡
        no_new_content_count = 0  # è¿ç»­æ— æ–°å†…å®¹çš„æ¬¡æ•°
        
        while len(tweets) < num_tweets and scroll_attempts < max_scrolls:
            # æŸ¥æ‰¾æ¨æ–‡å…ƒç´ 
            tweet_elements = driver.find_elements(By.CSS_SELECTOR, 'article[data-testid="tweet"]')
            
            print(f"ğŸ“Š ç¬¬{scroll_attempts+1}æ¬¡æ‰«æï¼Œæ‰¾åˆ° {len(tweet_elements)} ä¸ªæ¨æ–‡å…ƒç´ ï¼Œå·²è·å– {len(tweets)} æ¡æ¨æ–‡", file=sys.stderr)
            
            previous_count = len(tweets)
            
            # æå–æ¨æ–‡æ•°æ®
            for element in tweet_elements:
                if len(tweets) >= num_tweets:
                    break
                
                try:
                    # æå–æ¨æ–‡æ–‡æœ¬
                    text_element = element.find_element(By.CSS_SELECTOR, '[data-testid="tweetText"]')
                    text = text_element.text if text_element else ''
                    
                    # æå–æ—¶é—´
                    try:
                        time_element = element.find_element(By.TAG_NAME, 'time')
                        created_at = time_element.get_attribute('datetime')
                    except:
                        created_at = ''
                    
                    # æå–é“¾æ¥
                    try:
                        link_elements = element.find_elements(By.CSS_SELECTOR, 'a[href*="/status/"]')
                        tweet_url = ''
                        for link in link_elements:
                            href = link.get_attribute('href')
                            if href and '/status/' in href and username.lower() in href.lower():
                                tweet_url = href
                                break
                    except:
                        tweet_url = ''
                    
                    # æå–äº’åŠ¨æ•°æ®
                    metrics = {
                        'replies': 0,
                        'retweets': 0,
                        'likes': 0,
                        'views': 0
                    }
                    
                    try:
                        # å›å¤æ•°
                        reply_elements = element.find_elements(By.CSS_SELECTOR, '[data-testid="reply"]')
                        if reply_elements:
                            reply_text = reply_elements[0].text
                            reply_match = re.search(r'(\d+)', reply_text.replace(',', ''))
                            if reply_match:
                                metrics['replies'] = int(reply_match.group(1))
                        
                        # è½¬æ¨æ•°
                        retweet_elements = element.find_elements(By.CSS_SELECTOR, '[data-testid="retweet"]')
                        if retweet_elements:
                            retweet_text = retweet_elements[0].text
                            retweet_match = re.search(r'(\d+)', retweet_text.replace(',', ''))
                            if retweet_match:
                                metrics['retweets'] = int(retweet_match.group(1))
                        
                        # ç‚¹èµæ•°
                        like_elements = element.find_elements(By.CSS_SELECTOR, '[data-testid="like"]')
                        if like_elements:
                            like_text = like_elements[0].text
                            like_match = re.search(r'(\d+)', like_text.replace(',', ''))
                            if like_match:
                                metrics['likes'] = int(like_match.group(1))
                    except:
                        pass
                    
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆå»é‡ï¼‰
                    tweet_id = tweet_url.split('/status/')[-1].split('?')[0] if tweet_url else ''
                    
                    if tweet_id and not any(t.get('id') == tweet_id for t in tweets):
                        tweet_data = {
                            'id': tweet_id,
                            'text': text,
                            'created_at': created_at,
                            'url': tweet_url,
                            'metrics': metrics
                        }
                        tweets.append(tweet_data)
                        print(f"  âœ“ æ¨æ–‡ {len(tweets)}: {text[:50]}...", file=sys.stderr)
                
                except Exception as e:
                    continue
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ¨æ–‡
            if len(tweets) == previous_count:
                no_new_content_count += 1
                if no_new_content_count >= 3:
                    print(f"âš ï¸  è¿ç»­3æ¬¡æœªè·å–åˆ°æ–°æ¨æ–‡ï¼Œåœæ­¢æŠ“å–", file=sys.stderr)
                    break
            else:
                no_new_content_count = 0
            
            # æ»šåŠ¨åŠ è½½æ›´å¤š
            if len(tweets) < num_tweets:
                # æ»šåŠ¨åˆ°åº•éƒ¨
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(5)  # å¢åŠ ç­‰å¾…æ—¶é—´è®©æ¨æ–‡åŠ è½½
                
                # å†å‘ä¸Šæ»šåŠ¨ä¸€ç‚¹ï¼Œå†å‘ä¸‹æ»šåŠ¨ï¼ˆè§¦å‘åŠ è½½ï¼‰
                driver.execute_script("window.scrollBy(0, -500);")
                time.sleep(1)
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(3)
                
                new_height = driver.execute_script("return document.body.scrollHeight")
                
                # å¦‚æœé«˜åº¦æ²¡å˜ï¼Œè¯´æ˜å¯èƒ½åˆ°åº•äº†ï¼Œä½†å†è¯•ä¸€æ¬¡
                if new_height == last_height:
                    # å¼ºåˆ¶æ»šåŠ¨æ›´å¤š
                    for _ in range(3):
                        driver.execute_script("window.scrollBy(0, 1000);")
                        time.sleep(2)
                    
                    final_height = driver.execute_script("return document.body.scrollHeight")
                    if final_height == last_height:
                        if no_new_content_count >= 2:
                            print(f"âš ï¸  é¡µé¢æ— æ³•åŠ è½½æ›´å¤šå†…å®¹", file=sys.stderr)
                            break
                    else:
                        last_height = final_height
                else:
                    last_height = new_height
                
                scroll_attempts += 1
        
        print(f"\nâœ… æˆåŠŸè·å– {len(tweets)} æ¡æ¨æ–‡", file=sys.stderr)
        return tweets
        
    except Exception as e:
        print(f"âŒ æŠ“å–å¤±è´¥: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        return tweets
    
    finally:
        driver.quit()
        print("ğŸ”’ æµè§ˆå™¨å·²å…³é—­", file=sys.stderr)


def save_to_markdown(username, tweets, output_file):
    """ä¿å­˜æ¨æ–‡åˆ°Markdownæ ¼å¼"""
    lines = [
        f"# ğŸ¦ @{username} çš„æ¨æ–‡\n",
        f"ğŸ“… è·å–æ—¶é—´ï¼š{datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}\n",
        f"ğŸ“Š æ¨æ–‡æ•°é‡ï¼š{len(tweets)} æ¡\n",
        f"ğŸ”§ è·å–æ–¹å¼ï¼šSeleniumæµè§ˆå™¨è‡ªåŠ¨åŒ–\n",
        "---\n",
    ]
    
    for i, tweet in enumerate(tweets, 1):
        created_at = tweet.get('created_at', 'æœªçŸ¥æ—¶é—´')
        if created_at:
            try:
                dt = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
                created_at = dt.strftime('%Y-%m-%d %H:%M')
            except:
                pass
        
        text = tweet.get('text', '')
        url = tweet.get('url', '')
        metrics = tweet.get('metrics', {})
        
        lines.append(f"\n## {i}. {created_at}\n")
        lines.append(f"{text}\n")
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats_parts = []
        if metrics.get('likes'):
            stats_parts.append(f"â¤ï¸ {metrics['likes']:,} ç‚¹èµ")
        if metrics.get('retweets'):
            stats_parts.append(f"ğŸ”„ {metrics['retweets']:,} è½¬æ¨")
        if metrics.get('replies'):
            stats_parts.append(f"ğŸ’¬ {metrics['replies']:,} å›å¤")
        if metrics.get('views'):
            stats_parts.append(f"ğŸ‘ï¸ {metrics['views']:,} æµè§ˆ")
        
        if stats_parts:
            lines.append("\n**äº’åŠ¨æ•°æ®**: " + " | ".join(stats_parts) + "\n")
        
        if url:
            lines.append(f"\nğŸ”— [æŸ¥çœ‹åŸæ¨æ–‡]({url})\n")
        
        lines.append("\n---\n")
    
    # å†™å…¥æ–‡ä»¶
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(''.join(lines))
    
    print(f"âœ… Markdownå·²ä¿å­˜åˆ°: {output_file}", file=sys.stderr)


def main():
    parser = argparse.ArgumentParser(description='Twitteræ¨æ–‡æŠ“å–å·¥å…·ï¼ˆSeleniumç‰ˆï¼‰')
    parser.add_argument('username', help='Twitterç”¨æˆ·åï¼ˆä¸å«@ç¬¦å·ï¼‰')
    parser.add_argument('-n', '--num', type=int, default=10,
                       help='è¦è·å–çš„æ¨æ–‡æ•°é‡ï¼ˆé»˜è®¤ï¼š10ï¼‰')
    parser.add_argument('-o', '--output', 
                       help='è¾“å‡ºMarkdownæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--login-user',
                       help='Twitterç™»å½•ç”¨æˆ·åï¼ˆå¯é€‰ï¼Œç™»å½•åå¯è·å–å®Œæ•´æ¨æ–‡ï¼‰')
    parser.add_argument('--login-pass',
                       help='Twitterç™»å½•å¯†ç ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--login-config', default='config/twitter_login.json',
                       help='ç™»å½•é…ç½®æ–‡ä»¶ï¼ˆé»˜è®¤ï¼šconfig/twitter_login.jsonï¼‰')
    
    args = parser.parse_args()
    
    # è·å–ç™»å½•ä¿¡æ¯
    login_user = args.login_user
    login_pass = args.login_pass
    
    # å¦‚æœæ²¡æœ‰ç›´æ¥æä¾›ç™»å½•ä¿¡æ¯ï¼Œå°è¯•ä»é…ç½®æ–‡ä»¶è¯»å–
    if not login_user and os.path.exists(args.login_config):
        try:
            with open(args.login_config, 'r') as f:
                login_config = json.load(f)
                login_user = login_config.get('username')
                login_pass = login_config.get('password')
                if login_user:
                    print(f"ğŸ“‹ ä»é…ç½®æ–‡ä»¶è¯»å–ç™»å½•ä¿¡æ¯: {login_user}", file=sys.stderr)
        except Exception as e:
            print(f"âš ï¸  è¯»å–ç™»å½•é…ç½®å¤±è´¥: {e}", file=sys.stderr)
    
    # è·å–æ¨æ–‡
    tweets = scrape_tweets(args.username, args.num, login_user, login_pass)
    
    if not tweets:
        print("âŒ æœªèƒ½è·å–åˆ°æ¨æ–‡", file=sys.stderr)
        sys.exit(1)
    
    # ç¡®å®šè¾“å‡ºè·¯å¾„
    if args.output:
        output_file = args.output
    else:
        output_dir = 'output'
        os.makedirs(output_dir, exist_ok=True)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_file = os.path.join(output_dir, f'{args.username}_{timestamp}.md')
    
    # ä¿å­˜ä¸ºMarkdown
    save_to_markdown(args.username, tweets, output_file)
    
    # åŒæ—¶ä¿å­˜JSON
    json_file = output_file.replace('.md', '.json')
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump({
            'username': args.username,
            'fetch_time': datetime.now().isoformat(),
            'count': len(tweets),
            'tweets': tweets
        }, f, ensure_ascii=False, indent=2)
    print(f"âœ… JSONå·²ä¿å­˜åˆ°: {json_file}", file=sys.stderr)
    
    print(f"\nğŸ‰ å®Œæˆï¼å…±è·å– {len(tweets)} æ¡æ¨æ–‡", file=sys.stderr)


if __name__ == '__main__':
    main()

