#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é›ªçƒç”¨æˆ·å‘æ–‡çˆ¬è™« - æ”¹è¿›ç‰ˆ
å¢å¼ºåæ£€æµ‹èƒ½åŠ›
"""

import sys
import json
import time
import argparse
import os
from datetime import datetime

try:
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
except ImportError:
    print("âŒ è¯·å…ˆå®‰è£…selenium: pip install selenium", file=sys.stderr)
    sys.exit(1)


def setup_driver(headless=True):
    """é…ç½®æµè§ˆå™¨ - å¢å¼ºåæ£€æµ‹"""
    chrome_options = Options()
    
    if headless:
        chrome_options.add_argument('--headless=new')
    
    # åŸºç¡€è®¾ç½®
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--disable-gpu')
    chrome_options.add_argument('--window-size=1920,1080')
    
    # æ›´çœŸå®çš„User-Agent
    chrome_options.add_argument('--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
    
    # ç¦ç”¨è‡ªåŠ¨åŒ–ç‰¹å¾
    chrome_options.add_argument('--disable-blink-features=AutomationControlled')
    chrome_options.add_experimental_option('excludeSwitches', ['enable-automation'])
    chrome_options.add_experimental_option('useAutomationExtension', False)
    
    # æ·»åŠ æ›´å¤šå‚æ•°
    chrome_options.add_argument('--lang=zh-CN,zh;q=0.9')
    chrome_options.add_argument('--disable-infobars')
    chrome_options.add_argument('--start-maximized')
    
    # è®¾ç½®æ›´å¤šprefs
    prefs = {
        'credentials_enable_service': False,
        'profile.password_manager_enabled': False,
        'profile.default_content_setting_values': {
            'notifications': 2
        }
    }
    chrome_options.add_experimental_option('prefs', prefs)
    
    driver = webdriver.Chrome(options=chrome_options)
    
    # æ³¨å…¥JavaScriptéšè—webdriver
    driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
        'source': '''
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined
            });
            Object.defineProperty(navigator, 'plugins', {
                get: () => [1, 2, 3, 4, 5]
            });
            Object.defineProperty(navigator, 'languages', {
                get: () => ['zh-CN', 'zh', 'en']
            });
            window.chrome = {
                runtime: {}
            };
        '''
    })
    
    return driver


def get_user_posts(driver, user_id, max_posts=20):
    """è·å–ç”¨æˆ·å‘æ–‡"""
    posts = []
    
    try:
        url = f"https://xueqiu.com/u/{user_id}"
        print(f"ğŸ“– è®¿é—®: {url}", file=sys.stderr)
        
        driver.get(url)
        
        # ç­‰å¾…æ›´é•¿æ—¶é—´è®©WAFéªŒè¯å®Œæˆ
        print("â³ ç­‰å¾…é¡µé¢åŠ è½½ï¼ˆ15ç§’ï¼‰...", file=sys.stderr)
        time.sleep(15)
        
        # æ£€æŸ¥æ˜¯å¦è¢«WAFæ‹¦æˆª
        page_source = driver.page_source
        if '_waf_' in page_source and 'renderData' in page_source:
            print("âš ï¸  æ£€æµ‹åˆ°WAFä¿æŠ¤ï¼Œå†ç­‰å¾…10ç§’...", file=sys.stderr)
            time.sleep(10)
            driver.refresh()
            time.sleep(10)
        
        # å°è¯•è·å–ç”¨æˆ·å
        username = "æœªçŸ¥ç”¨æˆ·"
        try:
            username_elem = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, ".profile-name, .user-name, h2.name"))
            )
            username = username_elem.text
            print(f"ğŸ‘¤ ç”¨æˆ·å: {username}", file=sys.stderr)
        except:
            print(f"âš ï¸  æ— æ³•è·å–ç”¨æˆ·å", file=sys.stderr)
        
        # æ»šåŠ¨åŠ è½½
        scroll_count = 0
        max_scrolls = 10
        
        while scroll_count < max_scrolls and len(posts) < max_posts:
            # æŸ¥æ‰¾å‘æ–‡ - å°è¯•æ‰€æœ‰å¯èƒ½çš„é€‰æ‹©å™¨
            post_elements = []
            selectors = [
                "article",
                "div[class*='status']",
                "div[class*='timeline']",
                "div[class*='card']",
                "li[class*='item']",
                ".timeline__item",
                ".status-item",
                ".card-item"
            ]
            
            for selector in selectors:
                post_elements = driver.find_elements(By.CSS_SELECTOR, selector)
                if post_elements:
                    print(f"ğŸ“Š ä½¿ç”¨ '{selector}' æ‰¾åˆ° {len(post_elements)} ä¸ªå…ƒç´ ", file=sys.stderr)
                    break
            
            if not post_elements:
                # å°è¯•é€šè¿‡é“¾æ¥æŸ¥æ‰¾
                all_links = driver.find_elements(By.TAG_NAME, "a")
                post_links = [link for link in all_links if link.get_attribute('href') and f'/u/{user_id}/' in link.get_attribute('href')]
                
                if post_links:
                    print(f"ğŸ“Š é€šè¿‡é“¾æ¥æ‰¾åˆ° {len(post_links)} æ¡å‘æ–‡", file=sys.stderr)
                    for link in post_links[:max_posts]:
                        try:
                            post_url = link.get_attribute('href')
                            post_id = post_url.split('/')[-1].split('?')[0]
                            post_text = link.text.strip()
                            
                            post_data = {
                                'id': post_id,
                                'user_id': user_id,
                                'username': username,
                                'url': post_url,
                                'title': post_text[:100] if post_text else 'æ— æ ‡é¢˜',
                                'content': post_text,
                                'scraped_at': datetime.now().isoformat()
                            }
                            
                            if post_data['id'] and not any(p.get('id') == post_data['id'] for p in posts):
                                posts.append(post_data)
                                print(f"âœ… [{len(posts)}/{max_posts}] {post_text[:40]}...", file=sys.stderr)
                        except:
                            continue
                    break
            else:
                # å¤„ç†æ‰¾åˆ°çš„å…ƒç´ 
                for elem in post_elements:
                    if len(posts) >= max_posts:
                        break
                    
                    try:
                        post_data = extract_post_data(elem, user_id, username)
                        if post_data and post_data.get('id'):
                            if not any(p.get('id') == post_data['id'] for p in posts):
                                posts.append(post_data)
                                print(f"âœ… [{len(posts)}/{max_posts}] {post_data.get('title', '')[:40]}...", file=sys.stderr)
                    except:
                        continue
            
            # æ»šåŠ¨
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(3)
            scroll_count += 1
        
        print(f"\nâœ… å…±è·å– {len(posts)} æ¡å‘æ–‡", file=sys.stderr)
        return posts
        
    except Exception as e:
        print(f"âŒ è·å–å¤±è´¥: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        return posts


def extract_post_data(elem, user_id, username):
    """æå–å‘æ–‡æ•°æ®"""
    post_data = {
        'user_id': user_id,
        'username': username,
        'scraped_at': datetime.now().isoformat()
    }
    
    # æå–é“¾æ¥å’ŒID - é›ªçƒçš„æ ¼å¼æ˜¯ /user_id/post_id
    try:
        links = elem.find_elements(By.TAG_NAME, "a")
        for link in links:
            href = link.get_attribute('href')
            # æŸ¥æ‰¾æ ¼å¼ä¸º /user_id/æ•°å­— çš„é“¾æ¥
            if href and f'/{user_id}/' in href:
                post_data['url'] = href
                post_data['id'] = href.split('/')[-1].split('?')[0]
                
                # å°è¯•æå–æ—¶é—´
                link_text = link.text.strip()
                if 'Â·' in link_text and ('æ¥è‡ª' in link_text or ':' in link_text):
                    post_data['published_at'] = link_text
                break
    except:
        pass
    
    # æå–è¢«å¼•ç”¨/è½¬å‘çš„åŸæ–‡
    quoted_text = None
    try:
        quote_selectors = [
            'blockquote.timeline__item__forward',
            '.timeline__item__forward',
            'blockquote',
            '.quote',
            '.forward'
        ]
        
        for selector in quote_selectors:
            try:
                quote_elem = elem.find_element(By.CSS_SELECTOR, selector)
                quoted_text = quote_elem.get_attribute('innerText') or quote_elem.get_attribute('textContent')
                if quoted_text and quoted_text.strip():
                    quoted_text = quoted_text.strip()
                    post_data['quoted_text'] = quoted_text
                    break
            except:
                continue
    except:
        pass
    
    # æå–æ–‡æœ¬å†…å®¹ - ä½¿ç”¨å¤šç§æ–¹æ³•
    content = None
    
    # æ–¹æ³•1: å°è¯•é€šè¿‡CSSé€‰æ‹©å™¨ç›´æ¥è·å–å†…å®¹åŒºåŸŸ
    try:
        content_selectors = [
            '.content--description',
            '.content',
            '.timeline__item__content',
            '.status-content'
        ]
        
        for selector in content_selectors:
            try:
                content_elem = elem.find_element(By.CSS_SELECTOR, selector)
                # ä½¿ç”¨ innerText æˆ– textContent
                content = content_elem.get_attribute('innerText') or content_elem.get_attribute('textContent')
                if content and content.strip():
                    content = content.strip()
                    # å¦‚æœå†…å®¹ä¸­åŒ…å«äº†å¼•ç”¨æ–‡æœ¬ï¼Œå»æ‰å¼•ç”¨éƒ¨åˆ†
                    if quoted_text and quoted_text in content:
                        content = content.replace(quoted_text, '').strip()
                    break
            except:
                continue
    except:
        pass
    
    # æ–¹æ³•2: å¦‚æœä¸Šé¢æ²¡æœ‰è·å–åˆ°ï¼Œå°è¯•ç”¨article.text
    if not content:
        try:
            full_text = elem.text.strip()
            if full_text:
                # å¦‚æœæœ‰å¼•ç”¨æ–‡æœ¬ï¼Œå…ˆå»æ‰
                if quoted_text and quoted_text in full_text:
                    full_text = full_text.replace(quoted_text, '').strip()
                
                # åˆ†å‰²æ–‡æœ¬ï¼Œé€šå¸¸ç¬¬ä¸€è¡Œæˆ–å‰å‡ è¡Œæ˜¯å†…å®¹
                lines = full_text.split('\n')
                
                # è·³è¿‡ç”¨æˆ·åå’Œæ—¶é—´è¡Œï¼Œæ‰¾åˆ°å®é™…å†…å®¹
                content_lines = []
                for line in lines:
                    line = line.strip()
                    # è·³è¿‡ç”¨æˆ·åã€æ—¶é—´ã€äº’åŠ¨æ•°æ®ç­‰
                    if line and line != username and not line.startswith('10-') and \
                       'æ¥è‡ª' not in line and 'è½¬å‘' not in line and 'è®¨è®º' not in line and \
                       'æ”¶è—' not in line and not line.isdigit():
                        content_lines.append(line)
                
                content = '\n'.join(content_lines) if content_lines else full_text
        except:
            pass
    
    # è®¾ç½®titleå’Œcontent
    if content:
        post_data['title'] = content[:100] if len(content) > 100 else content
        post_data['content'] = content
    
    return post_data


def save_to_markdown(posts, output_file):
    """ä¿å­˜ä¸ºMarkdown"""
    username = posts[0].get('username', 'æœªçŸ¥ç”¨æˆ·') if posts else 'æœªçŸ¥ç”¨æˆ·'
    
    lines = [
        f"# ğŸ“Š {username} - é›ªçƒå‘æ–‡\n",
        f"ğŸ“… æŠ“å–æ—¶é—´ï¼š{datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}\n",
        f"ğŸ“ å‘æ–‡æ•°é‡ï¼š{len(posts)}æ¡\n",
        "---\n",
    ]
    
    for i, post in enumerate(posts, 1):
        title = post.get('title', 'æ— æ ‡é¢˜')
        lines.append(f"\n## {i}. {title}\n")
        
        if post.get('published_at'):
            lines.append(f"ğŸ•’ **å‘å¸ƒæ—¶é—´**: {post['published_at']}\n")
        
        if post.get('url'):
            lines.append(f"ğŸ”— **é“¾æ¥**: {post['url']}\n")
        
        # å¦‚æœæœ‰è¢«å¼•ç”¨çš„åŸæ–‡ï¼Œæ˜¾ç¤ºå‡ºæ¥
        if post.get('quoted_text'):
            lines.append(f"\n### ğŸ“Œ å¼•ç”¨çš„åŸæ–‡:\n")
            quoted = post['quoted_text'].replace('\n', '\n> ')
            lines.append(f"> {quoted}\n")
        
        if post.get('content') and post.get('content') != title:
            lines.append(f"\n### ğŸ’¬ å›å¤å†…å®¹:\n")
            lines.append(f"{post['content']}\n")
        
        lines.append("\n---\n")
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(lines))
    
    return '\n'.join(lines)


def main():
    parser = argparse.ArgumentParser(description='é›ªçƒçˆ¬è™«æ”¹è¿›ç‰ˆ')
    parser.add_argument('--user-id', type=str, required=True, help='é›ªçƒç”¨æˆ·ID')
    parser.add_argument('--max-posts', type=int, default=20, help='æœ€å¤šè·å–çš„å‘æ–‡æ•°é‡')
    parser.add_argument('--output', type=str, default='../output/xueqiu.md', help='è¾“å‡ºæ–‡ä»¶')
    parser.add_argument('--visible', action='store_true', help='æ˜¾ç¤ºæµè§ˆå™¨')
    
    args = parser.parse_args()
    
    print("=" * 60, file=sys.stderr)
    print("ğŸ“Š é›ªçƒçˆ¬è™«æ”¹è¿›ç‰ˆ", file=sys.stderr)
    print("=" * 60, file=sys.stderr)
    print(f"ğŸ‘¤ ç”¨æˆ·ID: {args.user_id}", file=sys.stderr)
    print(f"ğŸ“ æœ€å¤šè·å–: {args.max_posts}æ¡", file=sys.stderr)
    print("=" * 60, file=sys.stderr)
    print("", file=sys.stderr)
    
    driver = setup_driver(headless=not args.visible)
    
    try:
        posts = get_user_posts(driver, args.user_id, args.max_posts)
        
        if posts:
            markdown = save_to_markdown(posts, args.output)
            print(f"\nğŸ’¾ å·²ä¿å­˜åˆ°: {args.output}", file=sys.stderr)
            print("\n" + markdown)
        else:
            print("âŒ æ²¡æœ‰è·å–åˆ°å‘æ–‡", file=sys.stderr)
            
    finally:
        driver.quit()


if __name__ == '__main__':
    main()

